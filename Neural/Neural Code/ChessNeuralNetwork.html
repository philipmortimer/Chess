<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<title>ChessNeuralNetwork.java</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<style type="text/css">
<!--
body {color: #000000; background-color: #ffffff; font-family: Monospaced}
pre {color: #000000; background-color: #ffffff; font-family: Monospaced}
table {color: #000000; background-color: #e9e8e2; font-family: Monospaced}
.string {color: #ce7b00}
.literal {color: #0000e6}
.comment {color: #969696}
.ST0 {color: #969696; font-family: Monospaced; font-weight: bold}
-->
</style>
</head>
<body>
<table width="100%"><tr><td align="center">C:\Users\mortimer\OneDrive - gowercollegeswansea.ac.uk\Documents\College\YEAR 12\COMPUTER SCIENCE\Books attempt\DataBase\PhilipM CS5 Software Development Neural Network train\src\philipm\cs5\software\development\neural\network\train\ChessNeuralNetwork.java</td></tr></table>
<pre>
  1 <span class="comment">/*</span>
  2 <span class="comment"> * To change this license header, choose License Headers in Project Properties.</span>
  3 <span class="comment"> * To change this template file, choose Tools | Templates</span>
  4 <span class="comment"> * and open the template in the editor.</span>
  5 <span class="comment"> */</span>
  6 <span class="literal">package</span> philipm.cs5.software.development.neural.network.train;
  7 
  8 <span class="literal">import</span> java.io.BufferedReader;
  9 <span class="literal">import</span> java.io.FileReader;
 10 <span class="literal">import</span> java.io.IOException;
 11 
 12 <span class="comment">/**</span>
 13 <span class="comment"> * </span><span class="ST0">This</span> <span class="ST0">is</span> <span class="ST0">a</span> <span class="ST0">neural</span> <span class="ST0">network</span> <span class="ST0">trained</span> <span class="ST0">by</span> <span class="ST0">me</span> <span class="ST0">to</span> <span class="ST0">play</span> <span class="ST0">chess</span><span class="ST0">.</span>
 14 <span class="comment"> * </span><span class="ST0">@author</span> <span class="comment">mortimer</span>
 15  <span class="comment">*/</span>
 16 <span class="literal">public</span> <span class="literal">class</span> ChessNeuralNetwork {
 17     <span class="literal">private</span> <span class="literal">static</span> <span class="literal">final</span> String BEST_NET_FILE_NAME=<span class="string">&quot;</span><span class="string">bestNet.txt</span><span class="string">&quot;</span>;<span class="comment">//stores the location of the text file that stores the best network architecture</span>
 18     <span class="literal">private</span> <span class="literal">final</span> <span class="literal">double</span>[] ALL_WEIGHTS_AND_BIASES;<span class="comment">//stores all weights and biases of the neural network</span>
 19     <span class="literal">private</span> <span class="literal">final</span> <span class="literal">int</span>[]NETWORK_STRUCTURE;<span class="comment">//stores the network structure</span>
 20     <span class="literal">private</span> <span class="literal">final</span> <span class="literal">int</span> NET_LENGTH;<span class="comment">//stores the length of the net architecture</span>
 21     <span class="literal">private</span> <span class="literal">final</span> <span class="literal">double</span>[] NET_ACTIVATIONS;<span class="comment">//stores the network activation values</span>
 22     <span class="comment">/**</span>
 23 <span class="comment">     * </span><span class="ST0">Loads</span> <span class="ST0">the</span> <span class="ST0">neural</span> <span class="ST0">network</span> <span class="ST0">stored</span> <span class="ST0">in</span> <span class="ST0">the</span><span class="ST0"> &quot;</span><span class="ST0">bestNet</span><span class="ST0">.</span><span class="ST0">txt</span><span class="ST0">&quot; </span><span class="ST0">file</span><span class="ST0">.</span>
 24 <span class="comment">     * </span><span class="ST0">@param</span> <span class="comment">NETWORK_STRUCTURE</span> <span class="comment">The</span> <span class="comment">network</span> <span class="comment">structure</span> <span class="comment">of</span> <span class="comment">the</span> <span class="comment">neural</span> <span class="comment">network</span>
 25 <span class="comment">     * </span><span class="ST0">@throws</span> <span class="comment">java</span><span class="comment">.</span><span class="comment">io</span><span class="comment">.</span><span class="comment">IOException</span> <span class="comment">An</span> <span class="comment">IOException</span> <span class="comment">may</span> <span class="comment">be</span> <span class="comment">thrown</span> <span class="comment">when</span> <span class="comment">reading</span> <span class="comment">the</span> <span class="comment">values</span> <span class="comment">of</span> <span class="comment">the</span> <span class="comment">network</span><span class="comment">&#39;</span><span class="comment">s</span> <span class="comment">weights</span> <span class="comment">and</span> <span class="comment">biases</span> <span class="comment">from</span><span class="comment"> &quot;</span><span class="comment">bestNet</span><span class="comment">.</span><span class="comment">txt</span><span class="comment">&quot;</span>
 26      <span class="comment">*/</span>
 27     <span class="literal">public</span> ChessNeuralNetwork(<span class="literal">final</span> <span class="literal">int</span>[] NETWORK_STRUCTURE)<span class="literal">throws</span> IOException{
 28         <span class="literal">this</span>.NETWORK_STRUCTURE= NETWORK_STRUCTURE;
 29         NET_LENGTH=NETWORK_STRUCTURE.length;
 30         <span class="literal">int</span> totNeurons=NETWORK_STRUCTURE[0]+NETWORK_STRUCTURE[1];
 31         <span class="literal">int</span> noOfWeightsAndBiases=NETWORK_STRUCTURE[0]*NETWORK_STRUCTURE[1]+NETWORK_STRUCTURE[1];<span class="comment">//stores the number of weights and biases in the network</span>
 32         <span class="literal">for</span>(<span class="literal">int</span> i=2;i&lt;NETWORK_STRUCTURE.length;i++){<span class="comment">//calculates the total number of weights and biases</span>
 33             noOfWeightsAndBiases=noOfWeightsAndBiases+NETWORK_STRUCTURE[i]*NETWORK_STRUCTURE[i-1]+NETWORK_STRUCTURE[i];
 34             totNeurons=totNeurons+NETWORK_STRUCTURE[i];
 35         }
 36         <span class="literal">if</span>(NETWORK_STRUCTURE.length&gt;2){
 37             totNeurons=totNeurons-NETWORK_STRUCTURE[NET_LENGTH-1];
 38         }
 39         NET_ACTIVATIONS=<span class="literal">new</span> <span class="literal">double</span>[totNeurons];
 40         ALL_WEIGHTS_AND_BIASES=<span class="literal">new</span> <span class="literal">double</span>[noOfWeightsAndBiases];<span class="comment">//creates array storing all weights and biases</span>
 41         <span class="comment">//reads network architecture from text file</span>
 42         FileReader read = <span class="literal">new</span> FileReader(BEST_NET_FILE_NAME);
 43         <span class="literal">int</span> i=0;<span class="comment">//stores the index of all weights and biases to be accessed</span>
 44         BufferedReader buffRead = <span class="literal">new</span> BufferedReader(read);
 45         String lineRead;<span class="comment">//stores the line read</span>
 46         <span class="literal">while</span>((lineRead=buffRead.readLine())!=<span class="literal">null</span>){<span class="comment">//loads values of neural network</span>
 47             ALL_WEIGHTS_AND_BIASES[i]=Double.parseDouble(lineRead);
 48             i++;
 49         }
 50         buffRead.close();read.close();
 51     }
 52     <span class="comment">/**</span>
 53 <span class="comment">     * </span><span class="ST0">Feeds</span> <span class="ST0">data</span> <span class="ST0">through</span> <span class="ST0">the</span> <span class="ST0">network</span> <span class="ST0">and</span> <span class="ST0">returns</span> <span class="ST0">the</span> <span class="ST0">network</span><span class="ST0">&#39;</span><span class="ST0">s</span> <span class="ST0">output</span>
 54 <span class="comment">     * </span><span class="ST0">@param</span> <span class="comment">input</span> <span class="comment">The</span> <span class="comment">input</span>
 55 <span class="comment">     * </span><span class="ST0">@return</span> <span class="comment">The</span> <span class="comment">output</span>
 56      <span class="comment">*/</span>
 57     <span class="literal">public</span> <span class="literal">double</span>[] feedThroughNet(<span class="literal">int</span>[]input){
 58         <span class="literal">int</span> currentIndexForAll=0;<span class="comment">//stores the current index for all weights and biases</span>
 59         <span class="literal">int</span> activsIndex=0;
 60         <span class="literal">double</span> out[]=<span class="literal">new</span> <span class="literal">double</span>[NETWORK_STRUCTURE[NET_LENGTH-1]];
 61         <span class="literal">int</span> startOfPrevLayer=0;
 62         <span class="literal">for</span>(;activsIndex&lt;input.length;activsIndex++){
 63            NET_ACTIVATIONS[activsIndex]=input[activsIndex];
 64         }
 65         <span class="literal">double</span> sum;<span class="comment">//stores the sum that amounts to the input to the node</span>
 66         <span class="literal">for</span>(<span class="literal">int</span> layerIndex=1;layerIndex&lt;NET_LENGTH-1;layerIndex++){
 67             <span class="literal">for</span>(<span class="literal">int</span> neuronInLayer=0;neuronInLayer&lt;NETWORK_STRUCTURE[layerIndex];neuronInLayer++){<span class="comment">//loops through every neuron in current layer</span>
 68                 sum=ALL_WEIGHTS_AND_BIASES[currentIndexForAll];<span class="comment">//sets the sum equal to the bias</span>
 69                 currentIndexForAll++;
 70                 <span class="literal">for</span>(<span class="literal">int</span> neuronInPrevLayer=0;neuronInPrevLayer&lt;NETWORK_STRUCTURE[layerIndex-1];neuronInPrevLayer++){<span class="comment">//sums weights in previous layer to calculate input value to node</span>
 71                     sum=sum+NET_ACTIVATIONS[startOfPrevLayer+neuronInPrevLayer]*ALL_WEIGHTS_AND_BIASES[currentIndexForAll];
 72                     currentIndexForAll++;
 73                 }
 74                 NET_ACTIVATIONS[activsIndex]=reLu(sum);
 75                 activsIndex++;
 76             }
 77             startOfPrevLayer=startOfPrevLayer+NETWORK_STRUCTURE[layerIndex-1];
 78         }
 79         <span class="comment">//calculates output</span>
 80         <span class="literal">for</span>(<span class="literal">int</span> neuronInLayer=0;neuronInLayer&lt;NETWORK_STRUCTURE[NET_LENGTH-1];neuronInLayer++){<span class="comment">//loops through every neuron in output layer</span>
 81             sum=ALL_WEIGHTS_AND_BIASES[currentIndexForAll];<span class="comment">//sets the sum equal to the bias</span>
 82             currentIndexForAll++;
 83             <span class="literal">for</span>(<span class="literal">int</span> neuronInPrevLayer=0;neuronInPrevLayer&lt;NETWORK_STRUCTURE[NET_LENGTH-2];neuronInPrevLayer++){<span class="comment">//sums weights in previous layer to calculate input value to node</span>
 84                 sum=sum+NET_ACTIVATIONS[startOfPrevLayer+neuronInPrevLayer]*ALL_WEIGHTS_AND_BIASES[currentIndexForAll];
 85                 currentIndexForAll++;
 86             }
 87             out[neuronInLayer]=sum;
 88         }
 89         softmax(out);
 90         <span class="literal">return</span> out;   
 91     }
 92     <span class="comment">/**</span>
 93 <span class="comment">     * </span><span class="ST0">Executes</span> <span class="ST0">the</span> <span class="ST0">reLu</span> <span class="ST0">function</span>
 94 <span class="comment">     * </span><span class="ST0">@param</span> <span class="comment">x</span> <span class="comment">The</span> <span class="comment">input</span>
 95 <span class="comment">     * </span><span class="ST0">@return</span> <span class="comment">The</span> <span class="comment">output</span>
 96      <span class="comment">*/</span>
 97     <span class="literal">private</span> <span class="literal">static</span> <span class="literal">double</span> reLu(<span class="literal">double</span> x){
 98         <span class="literal">if</span>(x&gt;0.0){
 99             <span class="literal">return</span> x;
100         }<span class="literal">else</span>{
101             <span class="literal">return</span> 0.0;
102         }
103     }
104     <span class="comment">/**</span>
105 <span class="comment">     * </span><span class="ST0">Performs</span> <span class="ST0">the</span> <span class="ST0">softmax</span> <span class="ST0">function</span> <span class="ST0">on</span> <span class="ST0">the</span> <span class="ST0">inputted</span> <span class="ST0">array</span>
106 <span class="comment">     * </span><span class="ST0">@param</span> <span class="comment">input</span> <span class="comment">The</span> <span class="comment">array</span> <span class="comment">to</span> <span class="comment">perform</span> <span class="comment">the</span> <span class="comment">softmax</span> <span class="comment">function</span> <span class="comment">on</span>
107      <span class="comment">*/</span>
108     <span class="literal">private</span> <span class="literal">static</span> <span class="literal">void</span> softmax(<span class="literal">double</span>[]input){
109         input[0]=Math.exp(input[0]);
110         <span class="literal">double</span> sum=input[0];<span class="comment">//stores the sum of the exponentials</span>
111         <span class="literal">for</span>(<span class="literal">int</span> i=1;i&lt;input.length;i++){
112             input[i]=Math.exp(input[i]);
113             sum=sum+input[i];
114         }
115         <span class="literal">for</span>(<span class="literal">int</span> i=0;i&lt;input.length;i++){
116             input[i]=input[i]/sum;
117         }
118     }
119      <span class="comment">/* Tests the network&#39;s accuracy</span>
120 <span class="comment">     * @param testData The test data to use when testing accuracy</span>
121 <span class="comment">     * @return The accuracy and loss of the system as an array of length 2. Element 0 corresponds to the accuracy, whilst element 1 is the loss.</span>
122 <span class="comment">     */</span>
123     <span class="literal">public</span> <span class="literal">double</span>[]testAccuracy(<span class="literal">int</span> testData[][]){
124         <span class="literal">double</span> time = System.currentTimeMillis();<span class="comment">//used to calculate how long it takes to test the system</span>
125         <span class="literal">int</span> totalCorrect=0;<span class="literal">double</span>[]out;
126         <span class="literal">double</span>[]desiredOut = <span class="literal">new</span> <span class="literal">double</span>[2];
127         <span class="literal">double</span> averageLoss=0.0;<span class="literal">int</span> greatestIndex;<span class="literal">double</span> err;
128         <span class="literal">double</span> diff;
129         <span class="literal">int</span>[]netInput=<span class="literal">new</span> <span class="literal">int</span>[PhilipMCS5SoftwareDevelopmentNeuralNetworkTrain.WIDTH_OF_DATA-2];<span class="comment">//stores the network input</span>
130         <span class="literal">for</span>(<span class="literal">int</span> y=0;y&lt;testData.length;y++){<span class="comment">//loops trhough every item in the test dataset</span>
131             desiredOut[0]=testData[y][0];<span class="comment">//gets the desired output of the neural network</span>
132             desiredOut[1]=testData[y][1];
133             <span class="literal">for</span>(<span class="literal">int</span> x=2;x&lt;testData[0].length;x++){<span class="comment">//generates the input to the neural network</span>
134                 netInput[x-2]=testData[y][x];
135             }
136             out=<span class="literal">this</span>.feedThroughNet(netInput);<span class="comment">//passes the network input throught the neural network</span>
137             greatestIndex=0;<span class="comment">//determines whether out[0] or out[1] is biggest</span>
138             <span class="literal">if</span>(out[1]&gt;out[0]){
139                 greatestIndex=1;
140             }
141             <span class="literal">if</span>(desiredOut[greatestIndex]==1.0){<span class="comment">//checks to see if network is correct</span>
142                 totalCorrect++;
143             }
144            <span class="comment">/* diff=out[0]-desiredOut[0];</span>
145 <span class="comment">            err=diff*diff;*/</span>
146            err=0;
147             <span class="comment">//calculates the loss of the network</span>
148             <span class="literal">for</span>(<span class="literal">int</span> i=0;i&lt;out.length;i++){
149                 err = err+(desiredOut[i]*Math.log(out[i]));<span class="comment">//categorical cross entropy loss is employed -  this makes the assumption that the desired output is a one hot vector</span>
150                 
151             }err=err*-1.0;
152             averageLoss=averageLoss+(err);<span class="comment">//adds loss to total loss</span>
153         }
154         
155         <span class="literal">double</span> accuracy = (<span class="literal">double</span>)totalCorrect/(<span class="literal">double</span>)PhilipMCS5SoftwareDevelopmentNeuralNetworkTrain.NO_OF_TEST_BOARDS;<span class="comment">//calculates the accuracy of the network</span>
156         accuracy= accuracy*100.0;
157         averageLoss=averageLoss/(<span class="literal">double</span>)PhilipMCS5SoftwareDevelopmentNeuralNetworkTrain.NO_OF_TEST_BOARDS;<span class="comment">//calculates the average loss</span>
158         System.out.println(<span class="string">&quot;</span><span class="string">Testing time: </span><span class="string">&quot;</span>+((System.currentTimeMillis()-time)/1000.0)+<span class="string">&quot;</span><span class="string"> seconds . Total correct: </span><span class="string">&quot;</span>+totalCorrect+<span class="string">&quot;</span><span class="string"> out of </span><span class="string">&quot;</span>+PhilipMCS5SoftwareDevelopmentNeuralNetworkTrain.NO_OF_TEST_BOARDS);
159         <span class="literal">double</span> ret[]={accuracy,averageLoss};
160         <span class="literal">return</span> ret;
161     }
162 }
163 
</pre></body>
</html>
